<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Finance Web Scraping - Juan Benitez</title>
    <link rel="stylesheet" href="css/styles.css">
    <style>
        .toc {
            margin-bottom: 20px;
        }
        .toc-header {
            cursor: pointer;
            background-color: #f1f1f1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .toc-content {
            display: none;
            padding: 10px;
            border: 1px solid #ddd;
            border-top: none;
            border-radius: 0 0 4px 4px;
        }
        .toc-content ul {
            list-style-type: none;
            padding-left: 20px;
        }
        .toc-content ul ul {
            padding-left: 40px;
        }
        .toc-content a {
            text-decoration: none;
            color: #0066cc;
        }
        .toc-content a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <header>
        <h1>Finance Web Scraping</h1>
        <a href="index.html" class="back-link">Back to Home</a>
    </header>
    <main>
        <section class="project-details">
            <div class="toc">
                <div class="toc-header">Content (Click to expand)</div>
                <div class="toc-content">
                    <ul>
                        <li><a href="#introduction">Introduction</a>
                            <ul>
                                <li><a href="#overview">Overview</a></li>
                                <li><a href="#use-case">Use case</a></li>
                                <li><a href="#github-code">GitHub code</a></li>
                            </ul>
                        </li>
                        <li><a href="#python-code-analysis">Python Code and Analysis</a>
                            <ul>
                                <li><a href="#step1">Step 1: import packages</a></li>
                                <li><a href="#step2">Step 2: generate needed lists</a></li>
                                <li><a href="#step3">Step 3: Loop for page scraping</a></li>
                                <li><a href="#step4">Step 4: Table extraction</a></li>
                                <li><a href="#step5">Step 5: Rows extraction</a></li>
                                <li><a href="#step6">Step 6: Data storage in lists</a></li>
                                <li><a href="#step7">Step 7: Dataframe creation</a></li>
                                <li><a href="#step8">Step 8: Data cleaning and formatting of numeric columns</a></li>
                            </ul>
                        </li>
                        <li><a href="#conclusions">Conclusions</a></li>
                    </ul>
                </div>
            </div>

            <h2 id="introduction">Introduction</h2>
            <h3 id="overview">Overview</h3>
            <p>In this project, we will develop a web scraping process to gather detailed information on the financial fundamentals of publicly traded companies. Instead of relying on the conventional Yahoo Finance API, we will utilize Python's requests and BeautifulSoup libraries, enabling more precise and flexible data extraction. It is important to note that the purpose of this project is purely educational, aimed at demonstrating the technical implementation. For ethical and legal reasons, the specific website from which the data is sourced will not be disclosed, as its use and replication require appropriate authorization.</p>

            <h3 id="use-case">Use case</h3>
            <p>This project focuses on web scraping to extract financial data, which can be used for investment analysis, market research, or building financial dashboards. Such data is valuable for financial analysts, investors, or data scientists looking to analyze company fundamentals without relying on paid APIs or manual data collection. Additionally, this approach allows for continuously updated datasets, without depending on third parties. It is ideal for building customized investment dashboards or performing comparative analysis of companies efficiently.</p>
            <p>Other general applications of web scraping include:</p>
            <li>Collecting information about products and their prices across multiple websites for comparison or analyzing price trends in e-commerce.</li>
            <li>Extracting data about competitors’ products, services, or pricing to adjust commercial and marketing strategies.</li>
            <li>Gathering large volumes of public data from websites, such as articles, research papers, or surveys, for analysis in scientific studies.</li>
            <li>Extracting headlines, articles, or mentions of specific topics from news sites, blogs, or social media to conduct trend analysis or market studies.</li>
            <li>Using scraping to automatically fill out online forms, such as in service subscriptions or lead generation applications.</li>
            <p>Web scraping is a powerful tool for large-scale data collection from websites, enabling businesses and analysts to access updated information without the cost of paid APIs or the labor-intensive task of manual data gathering.</p>

            <h3 id="github-code">GitHub code</h3>
            <p>The complete code for this project is available on GitHub: <a href="https://github.com/juanbenitez1/Finance-Scraping/blob/main/Scraping_Finance.py">Finance Web Scraping Code</a>.</p>

            <h2 id="python-code-analysis">Python Code and Analysis</h2>
            <p>This is the set of information we aim to extract:</p>
            <p style="text-align: center;"><strong>Figure 1:</strong> Market data</p>
            <img src="images/finance_scraping/1.jpg" alt="Market data Screenshot" class="centered-image-linearmodel">

            <h3 id="step1">Step 1: import packages</h3>
            <li><strong>requests:</strong> Used to make HTTP requests and get the content of the web page.</li>
            <li><strong>BeautifulSoup:</strong> Used to parse the HTML of the page to extract specific data.</li>
            <li><strong>pandas:</strong> Used to organize the extracted data in a DataFrame.</li>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Import Packages (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
import requests
from bs4 import BeautifulSoup
import pandas as pd 
                        </code></pre>
                    </div>
                </div>
            </div>
            
            <h3 id="step2">Step 2: generate needed lists</h3>
            <p>The list "pages" creates a list of numbers (sequence) representing the paging indexes for the website screener. The site displays 20 results per page, and the code assumes there are a total of 9981 items (actions).</p>
            <p>The formula (9981-21)//20 + 1 calculates how many pages there are:</p>
                <li>9981 - 21 = 9960 (subtract to adjust the range).</li>
                <li>9960 // 20 = 498 (number of complete pages).</li>
                <li>+ 1 to include the last page.</li>
            <p>The list sequence contains: [1, 21, 41, ..., 9961] (increments of 20).</p>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Lists to store the information (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
# This is a logic that allows us to navigate through all the website pages
pages = [1 + i*20 for i in range(0, (9981-21)//20 + 1)]

# Empty lists
No = []
Company = []
Sector = []
Industry = []
Country = []
PE = []
PEG = []
PB = []
Dividend = []
EPS = []
ROA = []
ROE = []
DE = []
ProfitM = []
Beta = []
Earnings = []
Volume = []
Price = []
Change = []
Ticker = []
                        </code></pre>
                    </div>
                </div>
            </div>    
            
            <h3 id="step3">Step 3: Loop for page scraping</h3>
            <p>Iterate over each index in sequence to access different pages of the screener.</p>
            <li><strong>main_url:</strong> Builds the URL for each page of the website screener.</li>
            <li><strong>headers:</strong> Simulates a browser (Chrome) to avoid server crashes.</li>
            <li><strong>requests.get:</strong> Performs an HTTP request to get the page content.</li>
            <li><strong>BeautifulSoup:</strong> Parses the HTML of the page to facilitate data extraction.</li>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Loop for scraping (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
for i in pages:
    main_url = 'https://****.com/screener.****='+str(i)
    headers = {"user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36"}
    main_response = requests.get(main_url, headers=headers)
    main_soup = BeautifulSoup(main_response.text,'html.parser')
                        </code></pre>
                    </div>
                </div>
            </div>

            <h3 id="step4">Step 4: Table extraction</h3>
            <li>Find the main table with the styled-table-new... class in the HTML.</li>
            <li>Extracts the header (<tr> with align='center').</li>
            <li>Gets all header cells (<th> with class table-header cursor-pointer).</li>
            <li>Stores column names in the cols list (e.g. “No”, “Ticker”, “Company”, etc.).</li>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Table extraction (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
table = main_soup.find('table',class_='styled-table-new is-rounded is-tabular-nums w-full screener_table')
header = table.find('tr',align='center')
header2 = header.find_all('th',class_='table-header cursor-pointer')
cols = []

for i in header2:
    col = i.text
    cols.append(col)
                        </code></pre>
                    </div>
                </div>
            </div>

            <h3 id="step5">Step 5: Rows extraction</h3>
            <p>Find all data and for each row:</p>
            <li>Extracts all cells (<td> with height='10').</li>
            <li>Saves the text of each cell in a temporary list (temp).</li>
            <li>Adds temp to the rows1 list, which contains the data of all rows.</li>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Rows extraction (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>    
rows = table.find_all('tr',valign='top')
rows1 = []
for i in rows:
    test = i.find_all('td',height='10')
    temp = []
    for j in test:
        temp.append(j.text)
    rows1.append(temp)
                        </code></pre>
                    </div>
                </div>
            </div>

            <h3 id="step6">Step 6: Data storage in lists</h3>
            <li>Iterates over the extracted rows (rows1).</li>
            <li>It assigns the values of each column to the corresponding list according to the cell index. For example, i[0] is the row number (No), i[1] is the ticker, etc.</li>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Data storage in lists (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
for i in rows1:
    No.append(i[0])
    Ticker.append(i[1])
    Company.append(i[2])
    Sector.append(i[3])
    Industry.append(i[4])
    Country.append(i[5])
    PE.append(i[7])
    PEG.append(i[8])
    PB.append(i[9])
    Dividend.append(i[10])
    EPS.append(i[11])
    ROA.append(i[12])
    ROE.append(i[13])
    DE.append(i[14])
    ProfitM.append(i[15])
    Beta.append(i[16])
    Earnings.append(i[17])
    Volume.append(i[18])
    Price.append(i[19])
    Change.append(i[20])
                        </code></pre>
                    </div>
                </div>
            </div>

            <h3 id="step7">Step 7: Dataframe creation</h3>
            <p>Create a pandas DataFrame with the lists as columns. The column names are more descriptive than the original ones (e.g. Symbol for Ticker, Debt_Equity for DE).</p>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Create and process dataset (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
df = pd.DataFrame({'Symbol':Ticker,
    'Company':Company,
    'Sector':Sector,
    'Industry':Industry,
    'Country':Country,
    'Price':Price,
    'ROA':ROA,
    'ROE':ROE,       
    'Beta':Beta,       
    'Debt_Equity':DE,                   
    'Price_Earning':PE,
    'EPS':EPS,                
    'PEG':PEG,
    'Change':Change,                   
    'Price_Book':PB,
    'Payment_Date':Earnings,                   
    'Dividend':Dividend,
    'Profit_Margin':ProfitM,
    'Volume':Volume
    })

df = df.applymap(lambda x: 'null' if x == '-' else x)

cols_to_modify = ['Price', 'ROA', 'ROE', 'Profit_Margin', 'Change',
                'Price_Earning', 'PEG', 'Price_Book', 'EPS',
                'Debt_Equity', 'Beta', 'Dividend']

for col in cols_to_modify:
    df[col] = df[col].astype(str)
    df[col] = df[col].str.replace('%', '')
    df[col] = df[col].str.replace('.', ',')
                        </code></pre>
                    </div>
                </div>
            </div>

            <h3 id="step8">Step 8: Data cleaning and formatting of numeric columns</h3>
            <p>Data cleaning:</p>
            <li>Replaces all '-' values in the DataFrame with 'null'. This ensures that empty or unavailable data is handled consistently.</li>
            <p>Numeric columns formatting</p>
            <ol>
                <li>Selects columns containing numeric values or percentages.</li>
                <li>Converts each column to type str for manipulation.</li>
                <li>Removes the percent symbol (%).</li>
                <li>Replaces the decimal point (.) with a comma (,), probably to comply with a regional format (for example, in some countries the comma is used as a decimal separator).</li>
            </ol>
            <div class="accordion">
                <div class="accordion-item">
                    <button class="accordion-header">Create and process dataset (Click to expand code)</button>
                    <div class="accordion-content">
                        <pre><code>
df = df.applymap(lambda x: 'null' if x == '-' else x)

cols_to_modify = ['Price', 'ROA', 'ROE', 'Profit_Margin', 'Change',
                'Price_Earning', 'PEG', 'Price_Book', 'EPS',
                'Debt_Equity', 'Beta', 'Dividend']

for col in cols_to_modify:
    df[col] = df[col].astype(str)
    df[col] = df[col].str.replace('%', '')
    df[col] = df[col].str.replace('.', ',')
                        </code></pre>
                    </div>
                </div>
            </div>
            
            <p>Finally, we arrived at the desired output. We can export it to different formats such as csv, excel, json, among others.</p>
            <p style="text-align: center;"><strong>Figure 2:</strong> Scraped market data</p>
            <img src="images/finance_scraping/2.jpg" alt="Market data Screenshot" class="centered-image-linearmodel">
 
            <h2 id="conclusions">Conclusions</h2>
            <p>Thus, we can see how, using basic Python libraries such as <code>requests</code>, <code>BeautifulSoup</code>, and <code>pandas</code>, it is possible to efficiently and structurally extract financial data from websites. This approach enables the collection of valuable information for further analysis. If you want to explore one of the practical applications of this data extraction, I invite you to check out my Power BI report, where I have used this data to create an interactive dashboard that supports my investment decision-making. You can view it by clicking <a href="market-fundamentals-analysis.html">here</a>.</p>
        </section>
    </main>
    <script>
        // JavaScript para manejar el accordion
        document.querySelectorAll('.accordion-header').forEach(button => {
            button.addEventListener('click', () => {
                const content = button.nextElementSibling;
                const isOpen = content.style.display === 'block';

                // Cerrar todos los contenidos abiertos
                document.querySelectorAll('.accordion-content').forEach(item => {
                    item.style.display = 'none';
                });

                // Mostrar u ocultar el contenido clicado
                content.style.display = isOpen ? 'none' : 'block';
            });
        });

        // JavaScript para manejar el índice desplegable
        document.querySelector('.toc-header').addEventListener('click', () => {
            const content = document.querySelector('.toc-content');
            const isOpen = content.style.display === 'block';
            content.style.display = isOpen ? 'none' : 'block';
        });
    </script>
</body>
</html>